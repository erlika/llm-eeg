{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM-EEG Framework - Phase 2: Data Loading & Processing\n",
    "\n",
    "This notebook demonstrates the complete Phase 2 implementation for the LLM-EEG framework,\n",
    "specifically designed for the BCI Competition IV-2a dataset.\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Phase 2 Components:**\n",
    "- **Data Loaders**: `BCICIV2aLoader` for loading MAT files\n",
    "- **Preprocessing**: Bandpass filter (8-30Hz), Notch filter (50/60Hz), Normalization\n",
    "- **Validation**: Data structure validation and signal quality assessment\n",
    "- **PyTorch Integration**: `EEGDataset` with train/val/test splitting\n",
    "\n",
    "**Dataset Information:**\n",
    "- 9 subjects (A01-A09)\n",
    "- 4 motor imagery classes (left hand, right hand, feet, tongue)\n",
    "- 22 EEG + 3 EOG channels\n",
    "- 250 Hz sampling rate\n",
    "- 288 trials per session (48 per class × 6 runs)\n",
    "\n",
    "**Google Drive Dataset:**\n",
    "- URL: https://drive.google.com/drive/folders/14tFFsegwr6oYF4wUuf_mjNOAgfuQ_Bwk\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1: Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.2: Clone the repository\n",
    "!git clone https://github.com/erlika/llm-eeg.git\n",
    "%cd llm-eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.3: Install dependencies\n",
    "!pip install -q numpy scipy mne torch scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.4: Add src to Python path\n",
    "import sys\n",
    "sys.path.insert(0, '/content/llm-eeg')\n",
    "\n",
    "# Verify import\n",
    "from src.core.data_types import EEGData, TrialData\n",
    "print(\"✅ LLM-EEG framework imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.1: Configure data paths\n",
    "# Update this path to match your Google Drive folder structure\n",
    "DATA_DIR = '/content/drive/MyDrive/BCI_Data/dataset_2a'  # Adjust as needed\n",
    "\n",
    "# Alternative common paths:\n",
    "# DATA_DIR = '/content/drive/MyDrive/BCI_Competition_IV_2a'\n",
    "# DATA_DIR = '/content/drive/MyDrive/EEG/BCI_IV_2a'\n",
    "\n",
    "import os\n",
    "if os.path.exists(DATA_DIR):\n",
    "    files = os.listdir(DATA_DIR)\n",
    "    mat_files = [f for f in files if f.endswith('.mat')]\n",
    "    print(f\"✅ Found {len(mat_files)} MAT files in {DATA_DIR}\")\n",
    "    print(f\"Files: {sorted(mat_files)}\")\n",
    "else:\n",
    "    print(f\"❌ Directory not found: {DATA_DIR}\")\n",
    "    print(\"Please update DATA_DIR to your dataset location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.2: Dataset constants\n",
    "from src.data import (\n",
    "    BCI_IV_2A_EEG_CHANNELS,\n",
    "    BCI_IV_2A_EOG_CHANNELS, \n",
    "    BCI_IV_2A_SAMPLING_RATE,\n",
    "    BCI_IV_2A_CLASS_MAPPING,\n",
    "    BCI_IV_2A_EVENT_CODES,\n",
    "    BCI_IV_2A_TRIALS_PER_SESSION\n",
    ")\n",
    "\n",
    "print(\"=== BCI Competition IV-2a Dataset Constants ===\")\n",
    "print(f\"EEG Channels: {BCI_IV_2A_EEG_CHANNELS}\")\n",
    "print(f\"EOG Channels: {BCI_IV_2A_EOG_CHANNELS}\")\n",
    "print(f\"Sampling Rate: {BCI_IV_2A_SAMPLING_RATE} Hz\")\n",
    "print(f\"Trials per Session: {BCI_IV_2A_TRIALS_PER_SESSION}\")\n",
    "print(f\"\\nClass Mapping: {BCI_IV_2A_CLASS_MAPPING}\")\n",
    "print(f\"Event Codes: {BCI_IV_2A_EVENT_CODES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Custom Data Loader for BCI IV-2a\n",
    "\n",
    "The BCI Competition IV-2a MAT files have a specific nested structure:\n",
    "- `data` array with 9 elements (runs per session)\n",
    "- Each run contains: `X` (signals), `y` (labels), `trial` (markers), `fs` (sampling rate), etc.\n",
    "- Runs 0-2 have no MI trials; Runs 3-8 contain 48 trials each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.1: BCICIV2aLoader - Custom loader for BCI Competition IV-2a\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "from src.core.data_types import EEGData, EventMarker\n",
    "\n",
    "class BCICIV2aLoader:\n",
    "    \"\"\"\n",
    "    Data loader for BCI Competition IV-2a dataset.\n",
    "    \n",
    "    Handles the specific MAT file structure with nested data arrays.\n",
    "    Supports loading single subjects, extracting trials, and event parsing.\n",
    "    \n",
    "    Attributes:\n",
    "        sampling_rate: Signal sampling rate (250 Hz)\n",
    "        n_eeg_channels: Number of EEG channels (22)\n",
    "        n_eog_channels: Number of EOG channels (3)\n",
    "        include_eog: Whether to include EOG channels\n",
    "        class_mapping: Mapping from class labels to names\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        sampling_rate: int = 250,\n",
    "        include_eog: bool = False,\n",
    "        trial_duration: float = 4.0,\n",
    "        trial_offset: float = 0.0\n",
    "    ):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.n_eeg_channels = 22\n",
    "        self.n_eog_channels = 3\n",
    "        self.include_eog = include_eog\n",
    "        self.trial_duration = trial_duration\n",
    "        self.trial_offset = trial_offset\n",
    "        \n",
    "        # BCI IV-2a class mapping\n",
    "        self.class_mapping = {\n",
    "            1: 'left_hand',\n",
    "            2: 'right_hand', \n",
    "            3: 'feet',\n",
    "            4: 'tongue'\n",
    "        }\n",
    "        \n",
    "        # EEG channel names (10-20 system)\n",
    "        self.eeg_channel_names = [\n",
    "            'Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4',\n",
    "            'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6',\n",
    "            'CP3', 'CP1', 'CPz', 'CP2', 'CP4',\n",
    "            'P1', 'Pz', 'P2', 'POz'\n",
    "        ]\n",
    "        self.eog_channel_names = ['EOG1', 'EOG2', 'EOG3']\n",
    "        \n",
    "    def load(self, file_path: str) -> EEGData:\n",
    "        \"\"\"\n",
    "        Load EEG data from a BCI IV-2a MAT file.\n",
    "        \n",
    "        Args:\n",
    "            file_path: Path to the MAT file (e.g., A01T.mat)\n",
    "            \n",
    "        Returns:\n",
    "            EEGData object containing signals, events, and metadata\n",
    "        \"\"\"\n",
    "        print(f\"Loading: {file_path}\")\n",
    "        \n",
    "        # Load MAT file\n",
    "        mat_data = loadmat(file_path, struct_as_record=False, squeeze_me=True)\n",
    "        \n",
    "        # Extract data array (9 runs)\n",
    "        data_array = mat_data['data']\n",
    "        \n",
    "        # Concatenate signals and collect events from MI runs (3-8)\n",
    "        all_signals = []\n",
    "        all_events = []\n",
    "        sample_offset = 0\n",
    "        \n",
    "        for run_idx in range(len(data_array)):\n",
    "            run = data_array[run_idx]\n",
    "            \n",
    "            # Get signals (samples x channels)\n",
    "            signals = run.X\n",
    "            n_samples = signals.shape[0]\n",
    "            all_signals.append(signals)\n",
    "            \n",
    "            # Get labels and trial markers (only in runs 3-8)\n",
    "            if hasattr(run, 'y') and hasattr(run.y, '__len__') and len(run.y) > 0:\n",
    "                labels = run.y\n",
    "                trial_starts = run.trial\n",
    "                \n",
    "                for i, (start, label) in enumerate(zip(trial_starts, labels)):\n",
    "                    event = EventMarker(\n",
    "                        sample=int(start) + sample_offset,\n",
    "                        code=768 + int(label),  # Map to BCI IV-2a event codes\n",
    "                        label=self.class_mapping.get(int(label), f'class_{label}')\n",
    "                    )\n",
    "                    all_events.append(event)\n",
    "            \n",
    "            sample_offset += n_samples\n",
    "        \n",
    "        # Concatenate all signals\n",
    "        signals = np.vstack(all_signals)  # (total_samples, channels)\n",
    "        \n",
    "        # Select channels\n",
    "        if self.include_eog:\n",
    "            n_channels = self.n_eeg_channels + self.n_eog_channels\n",
    "            channel_names = self.eeg_channel_names + self.eog_channel_names\n",
    "        else:\n",
    "            n_channels = self.n_eeg_channels\n",
    "            channel_names = self.eeg_channel_names\n",
    "            signals = signals[:, :self.n_eeg_channels]\n",
    "        \n",
    "        # Transpose to (channels, samples)\n",
    "        signals = signals.T\n",
    "        \n",
    "        # Extract subject info from filename\n",
    "        import os\n",
    "        filename = os.path.basename(file_path)\n",
    "        subject_id = filename[:3] if len(filename) >= 3 else 'unknown'\n",
    "        session_type = filename[3] if len(filename) > 3 else 'T'\n",
    "        \n",
    "        # Create EEGData object\n",
    "        eeg_data = EEGData(\n",
    "            signals=signals,\n",
    "            sampling_rate=self.sampling_rate,\n",
    "            channel_names=channel_names,\n",
    "            events=all_events,\n",
    "            metadata={\n",
    "                'subject_id': subject_id,\n",
    "                'session_type': session_type,\n",
    "                'n_trials': len(all_events),\n",
    "                'n_runs': len(data_array),\n",
    "                'file_path': file_path\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"  ✅ Loaded: {signals.shape[0]} channels, {signals.shape[1]} samples\")\n",
    "        print(f\"  ✅ Events: {len(all_events)} trials\")\n",
    "        \n",
    "        return eeg_data\n",
    "    \n",
    "    def extract_trials(\n",
    "        self,\n",
    "        eeg_data: EEGData,\n",
    "        duration: Optional[float] = None,\n",
    "        offset: Optional[float] = None\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Extract fixed-length trials from continuous EEG data.\n",
    "        \n",
    "        Args:\n",
    "            eeg_data: EEGData object with events\n",
    "            duration: Trial duration in seconds (default: 4.0)\n",
    "            offset: Offset from event onset in seconds (default: 0.0)\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (trials, labels):\n",
    "                - trials: ndarray of shape (n_trials, n_channels, n_samples)\n",
    "                - labels: ndarray of shape (n_trials,)\n",
    "        \"\"\"\n",
    "        duration = duration or self.trial_duration\n",
    "        offset = offset or self.trial_offset\n",
    "        \n",
    "        samples_per_trial = int(duration * self.sampling_rate)\n",
    "        offset_samples = int(offset * self.sampling_rate)\n",
    "        \n",
    "        trials = []\n",
    "        labels = []\n",
    "        \n",
    "        for event in eeg_data.events:\n",
    "            # Get trial start/end\n",
    "            start = event.sample + offset_samples\n",
    "            end = start + samples_per_trial\n",
    "            \n",
    "            # Skip if out of bounds\n",
    "            if start < 0 or end > eeg_data.signals.shape[1]:\n",
    "                continue\n",
    "            \n",
    "            # Extract trial segment\n",
    "            trial = eeg_data.signals[:, start:end]\n",
    "            trials.append(trial)\n",
    "            \n",
    "            # Map event code to class label (0-3)\n",
    "            if event.code >= 769:\n",
    "                label = event.code - 769  # 769->0, 770->1, 771->2, 772->3\n",
    "            else:\n",
    "                label = event.code - 1  # Fallback\n",
    "            labels.append(label)\n",
    "        \n",
    "        trials = np.array(trials)  # (n_trials, n_channels, n_samples)\n",
    "        labels = np.array(labels)  # (n_trials,)\n",
    "        \n",
    "        print(f\"Extracted {len(trials)} trials, shape: {trials.shape}\")\n",
    "        return trials, labels\n",
    "\n",
    "print(\"✅ BCICIV2aLoader defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.2: Load a single subject\n",
    "import os\n",
    "\n",
    "# Initialize loader\n",
    "loader = BCICIV2aLoader(include_eog=False)\n",
    "\n",
    "# Load subject A01 training data\n",
    "subject_file = os.path.join(DATA_DIR, 'A01T.mat')\n",
    "eeg_data = loader.load(subject_file)\n",
    "\n",
    "print(f\"\\n=== EEG Data Summary ===\")\n",
    "print(f\"Shape: {eeg_data.signals.shape}\")\n",
    "print(f\"Sampling rate: {eeg_data.sampling_rate} Hz\")\n",
    "print(f\"Channels: {len(eeg_data.channel_names)}\")\n",
    "print(f\"Events: {len(eeg_data.events)}\")\n",
    "print(f\"Duration: {eeg_data.signals.shape[1] / eeg_data.sampling_rate:.1f} seconds\")\n",
    "print(f\"Metadata: {eeg_data.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.3: Extract trials\n",
    "trials, labels = loader.extract_trials(eeg_data)\n",
    "\n",
    "print(f\"\\n=== Trial Data ===\")\n",
    "print(f\"Trials shape: {trials.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "# Class distribution\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(f\"\\nClass distribution:\")\n",
    "for u, c in zip(unique, counts):\n",
    "    class_name = loader.class_mapping.get(u + 1, f'class_{u}')\n",
    "    print(f\"  Class {u} ({class_name}): {c} trials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.1: Validate EEG data structure\n",
    "from src.data.validators import DataValidator, ValidationResult\n",
    "\n",
    "validator = DataValidator()\n",
    "\n",
    "# Validate the loaded data\n",
    "result = validator.validate(eeg_data)\n",
    "\n",
    "print(\"=== Data Validation ===\")\n",
    "print(f\"Valid: {result.is_valid}\")\n",
    "\n",
    "if result.errors:\n",
    "    print(f\"\\n❌ Errors:\")\n",
    "    for error in result.errors:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "if result.warnings:\n",
    "    print(f\"\\n⚠️  Warnings:\")\n",
    "    for warning in result.warnings:\n",
    "        print(f\"  - {warning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.2: Signal quality assessment\n",
    "from src.data.validators import QualityChecker\n",
    "\n",
    "quality_checker = QualityChecker(sampling_rate=250)\n",
    "\n",
    "# Assess quality of trial data\n",
    "quality_report = quality_checker.assess_quality(trials)\n",
    "\n",
    "print(\"=== Signal Quality Report ===\")\n",
    "print(f\"Overall Score: {quality_report.get('overall_score', 'N/A'):.3f}\")\n",
    "print(f\"\\nMetrics:\")\n",
    "for key, value in quality_report.items():\n",
    "    if key != 'overall_score' and not isinstance(value, (list, np.ndarray)):\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5.1: Create standard preprocessing pipeline\n",
    "from src.preprocessing import (\n",
    "    PreprocessingPipeline,\n",
    "    create_standard_pipeline,\n",
    "    BandpassFilter,\n",
    "    NotchFilter,\n",
    "    Normalization\n",
    ")\n",
    "\n",
    "# Standard pipeline: Notch -> Bandpass -> Normalization\n",
    "pipeline = create_standard_pipeline(\n",
    "    sampling_rate=250,\n",
    "    notch_freq=50.0,        # Power line frequency (50 Hz EU, 60 Hz US)\n",
    "    low_freq=8.0,           # Lower cutoff (mu rhythm)\n",
    "    high_freq=30.0,         # Upper cutoff (beta rhythm)\n",
    "    normalize_method='zscore',\n",
    "    normalize_axis='channel'\n",
    ")\n",
    "\n",
    "print(\"=== Preprocessing Pipeline ===\")\n",
    "print(f\"Steps: {[s.name for s in pipeline.get_steps()]}\")\n",
    "for step in pipeline.get_steps():\n",
    "    print(f\"  - {step.name}: {step.get_parameters()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5.2: Apply preprocessing to trials\n",
    "print(f\"Before preprocessing: {trials.shape}, range: [{trials.min():.2f}, {trials.max():.2f}]\")\n",
    "\n",
    "# Initialize and process\n",
    "pipeline.initialize()\n",
    "trials_processed = pipeline.process(trials)\n",
    "\n",
    "print(f\"After preprocessing: {trials_processed.shape}, range: [{trials_processed.min():.2f}, {trials_processed.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5.3: Visualize preprocessing effects\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select a sample trial and channel\n",
    "trial_idx = 0\n",
    "channel_idx = 7  # C3 - important for motor imagery\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Time axis\n",
    "time = np.arange(trials.shape[2]) / 250.0\n",
    "\n",
    "# Raw signal\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(time, trials[trial_idx, channel_idx, :], 'b-', linewidth=0.5)\n",
    "ax1.set_title(f'Raw Signal - Trial {trial_idx}, Channel C3')\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_ylabel('Amplitude (μV)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Processed signal\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(time, trials_processed[trial_idx, channel_idx, :], 'g-', linewidth=0.5)\n",
    "ax2.set_title('Preprocessed Signal (Notch + Bandpass + Normalization)')\n",
    "ax2.set_xlabel('Time (s)')\n",
    "ax2.set_ylabel('Normalized Amplitude')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Power spectrum - Raw\n",
    "ax3 = axes[1, 0]\n",
    "from scipy.signal import welch\n",
    "freqs, psd_raw = welch(trials[trial_idx, channel_idx, :], fs=250, nperseg=256)\n",
    "ax3.semilogy(freqs, psd_raw, 'b-')\n",
    "ax3.axvline(x=8, color='r', linestyle='--', alpha=0.5, label='8 Hz')\n",
    "ax3.axvline(x=30, color='r', linestyle='--', alpha=0.5, label='30 Hz')\n",
    "ax3.axvline(x=50, color='orange', linestyle='--', alpha=0.5, label='50 Hz (line noise)')\n",
    "ax3.set_title('Power Spectrum - Raw')\n",
    "ax3.set_xlabel('Frequency (Hz)')\n",
    "ax3.set_ylabel('PSD')\n",
    "ax3.set_xlim([0, 60])\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Power spectrum - Processed\n",
    "ax4 = axes[1, 1]\n",
    "freqs, psd_proc = welch(trials_processed[trial_idx, channel_idx, :], fs=250, nperseg=256)\n",
    "ax4.semilogy(freqs, psd_proc, 'g-')\n",
    "ax4.axvline(x=8, color='r', linestyle='--', alpha=0.5, label='8 Hz')\n",
    "ax4.axvline(x=30, color='r', linestyle='--', alpha=0.5, label='30 Hz')\n",
    "ax4.set_title('Power Spectrum - Preprocessed (8-30 Hz bandpass)')\n",
    "ax4.set_xlabel('Frequency (Hz)')\n",
    "ax4.set_ylabel('PSD')\n",
    "ax4.set_xlim([0, 60])\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: PyTorch Dataset Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6.1: Create PyTorch Dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from src.datasets import EEGDataset, train_val_test_split\n",
    "\n",
    "# Create dataset from preprocessed trials\n",
    "dataset = EEGDataset(\n",
    "    trials=trials_processed,\n",
    "    labels=labels,\n",
    "    transform=None  # Already preprocessed\n",
    ")\n",
    "\n",
    "print(f\"=== PyTorch Dataset ===\")\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "print(f\"Sample shape: {dataset[0][0].shape}\")\n",
    "print(f\"Label type: {type(dataset[0][1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6.2: Split into train/validation/test sets\n",
    "train_data, val_data, test_data = train_val_test_split(\n",
    "    dataset,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    random_seed=42,\n",
    "    stratify=True\n",
    ")\n",
    "\n",
    "print(f\"\\n=== Data Split ===\")\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6.3: Create DataLoaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"\\n=== DataLoaders ===\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Verify batch\n",
    "sample_batch, sample_labels = next(iter(train_loader))\n",
    "print(f\"\\nSample batch shape: {sample_batch.shape}\")\n",
    "print(f\"Sample labels shape: {sample_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Multi-Subject Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7.1: Load multiple subjects\n",
    "def load_multiple_subjects(\n",
    "    data_dir: str,\n",
    "    subject_ids: List[str],\n",
    "    session_type: str = 'T',\n",
    "    include_eog: bool = False\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load and combine data from multiple subjects.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to dataset directory\n",
    "        subject_ids: List of subject IDs (e.g., ['A01', 'A02', 'A03'])\n",
    "        session_type: 'T' for training, 'E' for evaluation\n",
    "        include_eog: Whether to include EOG channels\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (trials, labels, subject_ids) arrays\n",
    "    \"\"\"\n",
    "    loader = BCICIV2aLoader(include_eog=include_eog)\n",
    "    \n",
    "    all_trials = []\n",
    "    all_labels = []\n",
    "    all_subject_ids = []\n",
    "    \n",
    "    for subject_id in subject_ids:\n",
    "        file_path = os.path.join(data_dir, f\"{subject_id}{session_type}.mat\")\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"⚠️  File not found: {file_path}\")\n",
    "            continue\n",
    "            \n",
    "        eeg_data = loader.load(file_path)\n",
    "        trials, labels = loader.extract_trials(eeg_data)\n",
    "        \n",
    "        all_trials.append(trials)\n",
    "        all_labels.append(labels)\n",
    "        all_subject_ids.extend([subject_id] * len(labels))\n",
    "    \n",
    "    # Concatenate\n",
    "    trials = np.concatenate(all_trials, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "    subject_ids_array = np.array(all_subject_ids)\n",
    "    \n",
    "    return trials, labels, subject_ids_array\n",
    "\n",
    "print(\"✅ load_multiple_subjects function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7.2: Load all subjects\n",
    "all_subject_ids = ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09']\n",
    "\n",
    "# Load all subjects (may take a few minutes)\n",
    "all_trials, all_labels, subject_array = load_multiple_subjects(\n",
    "    DATA_DIR,\n",
    "    all_subject_ids,\n",
    "    session_type='T'\n",
    ")\n",
    "\n",
    "print(f\"\\n=== All Subjects Combined ===\")\n",
    "print(f\"Total trials: {all_trials.shape}\")\n",
    "print(f\"Total labels: {all_labels.shape}\")\n",
    "print(f\"Unique subjects: {np.unique(subject_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7.3: Preprocess all subjects\n",
    "print(\"Preprocessing all trials...\")\n",
    "all_trials_processed = pipeline.process(all_trials)\n",
    "print(f\"✅ Preprocessed shape: {all_trials_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Cross-Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8.1: K-Fold Cross-Validation\n",
    "from src.datasets import create_cv_folds\n",
    "\n",
    "# Create dataset from all subjects\n",
    "full_dataset = EEGDataset(\n",
    "    trials=all_trials_processed,\n",
    "    labels=all_labels\n",
    ")\n",
    "\n",
    "# Create 5-fold CV splits\n",
    "cv_folds = create_cv_folds(\n",
    "    full_dataset,\n",
    "    n_folds=5,\n",
    "    random_seed=42,\n",
    "    stratify=True\n",
    ")\n",
    "\n",
    "print(f\"=== 5-Fold Cross-Validation ===\")\n",
    "for i, (train_data, val_data) in enumerate(cv_folds):\n",
    "    print(f\"Fold {i+1}: Train={len(train_data)}, Val={len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8.2: Leave-One-Subject-Out (LOSO) Cross-Validation\n",
    "def create_loso_splits(\n",
    "    trials: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    subject_ids: np.ndarray\n",
    ") -> List[Tuple[EEGDataset, EEGDataset, str]]:\n",
    "    \"\"\"\n",
    "    Create Leave-One-Subject-Out cross-validation splits.\n",
    "    \n",
    "    Args:\n",
    "        trials: All trial data\n",
    "        labels: All labels\n",
    "        subject_ids: Subject ID for each trial\n",
    "        \n",
    "    Returns:\n",
    "        List of (train_dataset, test_dataset, test_subject_id) tuples\n",
    "    \"\"\"\n",
    "    unique_subjects = np.unique(subject_ids)\n",
    "    splits = []\n",
    "    \n",
    "    for test_subject in unique_subjects:\n",
    "        # Test: single subject\n",
    "        test_mask = subject_ids == test_subject\n",
    "        # Train: all other subjects\n",
    "        train_mask = ~test_mask\n",
    "        \n",
    "        train_dataset = EEGDataset(\n",
    "            trials=trials[train_mask],\n",
    "            labels=labels[train_mask]\n",
    "        )\n",
    "        test_dataset = EEGDataset(\n",
    "            trials=trials[test_mask],\n",
    "            labels=labels[test_mask]\n",
    "        )\n",
    "        \n",
    "        splits.append((train_dataset, test_dataset, test_subject))\n",
    "    \n",
    "    return splits\n",
    "\n",
    "# Create LOSO splits\n",
    "loso_splits = create_loso_splits(all_trials_processed, all_labels, subject_array)\n",
    "\n",
    "print(f\"=== Leave-One-Subject-Out CV ===\")\n",
    "for train_data, test_data, subject in loso_splits:\n",
    "    print(f\"Test Subject {subject}: Train={len(train_data)}, Test={len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Simple Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9.1: Define a simple CNN classifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleEEGNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple CNN for EEG classification.\n",
    "    Input: (batch, channels, samples) = (batch, 22, 1000)\n",
    "    Output: (batch, n_classes) = (batch, 4)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_channels=22, n_samples=1000, n_classes=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Temporal convolution\n",
    "        self.conv1 = nn.Conv1d(n_channels, 32, kernel_size=25, padding=12)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        \n",
    "        # Second conv layer\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=10, padding=5)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        \n",
    "        # Calculate flattened size\n",
    "        self._flat_size = 64 * (n_samples // 16)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self._flat_size, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, channels, samples)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleEEGNet(n_channels=22, n_samples=1000, n_classes=4).to(device)\n",
    "\n",
    "print(f\"=== Model ===\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9.2: Training loop\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Training configuration\n",
    "n_epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "print(f\"=== Training ===\")\n",
    "for epoch in range(n_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    train_labels_list = []\n",
    "    \n",
    "    for batch_data, batch_labels in train_loader:\n",
    "        batch_data = batch_data.float().to(device)\n",
    "        batch_labels = batch_labels.long().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_preds.extend(preds.cpu().numpy())\n",
    "        train_labels_list.extend(batch_labels.cpu().numpy())\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = accuracy_score(train_labels_list, train_preds)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in val_loader:\n",
    "            batch_data = batch_data.float().to(device)\n",
    "            batch_labels = batch_labels.long().to(device)\n",
    "            \n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels_list.extend(batch_labels.cpu().numpy())\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = accuracy_score(val_labels_list, val_preds)\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1:2d}/{n_epochs}: \"\n",
    "              f\"Train Loss={train_loss:.4f}, Acc={train_acc:.4f} | \"\n",
    "              f\"Val Loss={val_loss:.4f}, Acc={val_acc:.4f}\")\n",
    "\n",
    "print(f\"\\n✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9.3: Evaluate on test set\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_labels_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data, batch_labels in test_loader:\n",
    "        batch_data = batch_data.float().to(device)\n",
    "        outputs = model(batch_data)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels_list.extend(batch_labels.numpy())\n",
    "\n",
    "test_acc = accuracy_score(test_labels_list, test_preds)\n",
    "\n",
    "print(f\"=== Test Results ===\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    test_labels_list, \n",
    "    test_preds,\n",
    "    target_names=['Left Hand', 'Right Hand', 'Feet', 'Tongue']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9.4: Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss plot\n",
    "ax1 = axes[0]\n",
    "ax1.plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "ax1.plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training & Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2 = axes[1]\n",
    "ax2.plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
    "ax2.plot(history['val_acc'], label='Val Accuracy', marker='s')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training & Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9.5: Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(test_labels_list, test_preds)\n",
    "class_names = ['Left Hand', 'Right Hand', 'Feet', 'Tongue']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix (Test Accuracy: {test_acc:.2%})')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 Complete!\n",
    "\n",
    "### Summary\n",
    "\n",
    "You have successfully completed Phase 2: Data Loading & Processing:\n",
    "\n",
    "1. **Data Loader**: `BCICIV2aLoader` for BCI Competition IV-2a MAT files\n",
    "2. **Trial Extraction**: Fixed-length trial segmentation from continuous data\n",
    "3. **Validation**: Data structure and signal quality validation\n",
    "4. **Preprocessing**: Standard pipeline (Notch + Bandpass + Normalization)\n",
    "5. **PyTorch Integration**: `EEGDataset` with train/val/test splitting\n",
    "6. **Multi-Subject Loading**: Load and combine multiple subjects\n",
    "7. **Cross-Validation**: K-Fold and Leave-One-Subject-Out (LOSO)\n",
    "8. **Training Example**: Simple CNN classifier with training loop\n",
    "\n",
    "### Next Steps: Phase 3 - Feature Extraction & Classification\n",
    "\n",
    "- Common Spatial Pattern (CSP) feature extraction\n",
    "- Filter Bank CSP (FBCSP)\n",
    "- Deep learning classifiers (EEGNet, DeepConvNet)\n",
    "- Advanced hyperparameter tuning\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "```python\n",
    "# Load data\n",
    "loader = BCICIV2aLoader()\n",
    "eeg_data = loader.load('A01T.mat')\n",
    "trials, labels = loader.extract_trials(eeg_data)\n",
    "\n",
    "# Preprocess\n",
    "pipeline = create_standard_pipeline(sampling_rate=250)\n",
    "trials_processed = pipeline.process(trials)\n",
    "\n",
    "# Create PyTorch dataset\n",
    "dataset = EEGDataset(trials_processed, labels)\n",
    "train_data, val_data, test_data = train_val_test_split(dataset)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
